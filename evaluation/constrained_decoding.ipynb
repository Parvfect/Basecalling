{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6894/6894 [00:12<00:00, 553.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 6894\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from crnn import CNN_BiGRU_Classifier\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from training_data import data_preproc, load_pre_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from greedy_decoder import GreedyCTCDecoder, beam_search_decoder\n",
    "from utils import get_actual_transcript, get_model_savepath, get_motifs_identified\n",
    "import torchaudio\n",
    "import datetime\n",
    "\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "# Loading the data\n",
    "dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\datasets\\empirical\\full_test_dataset_v4_spacers.pkl\"\n",
    "\n",
    "sampled_dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\datasets\\empirical\\sampled_test_dataset_v4_spacers.pkl\"\n",
    "\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\models\\empirical\\model_10_11_24.pth\"\n",
    "\n",
    "# Can add it this way - the function there is literal ass\n",
    "squiggle_column = ''\n",
    "label_column = ''\n",
    "\n",
    "X,y = data_preproc(dataset_path=sampled_dataset_path, chop_reads=1)\n",
    "print(f\"Number of samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading the model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_df = pd.read_pickle(dataset_path)\n",
    "\n",
    "output_classes = 19\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "labels_int = np.arange(output_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels=labels)\n",
    "\n",
    "# Model Parameters\n",
    "input_size = 1  # Number of input channels\n",
    "hidden_size = 256\n",
    "num_layers = 4\n",
    "output_size = output_classes  # Number of output classes\n",
    "dropout_rate = 0.2\n",
    "\n",
    "saved_model = True\n",
    "\n",
    "# Model Definition\n",
    "model = CNN_BiGRU_Classifier(input_size, hidden_size, num_layers, output_size, dropout_rate)\n",
    "\n",
    "if saved_model:\n",
    "    model_path = model_path\n",
    "    if device == torch.device('cpu'):\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "ctc_loss = nn.CTCLoss(zero_infinity=True)\n",
    "\n",
    "X_test, y_test = X, y\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "n_classes = output_classes\n",
    "step_sequence = 100\n",
    "window_overlap = 50\n",
    "length_per_sample = 150\n",
    "model_output_split_size = 1\n",
    "\n",
    "epochs = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_payload_spacer_sequence(payload):\n",
    "\n",
    "    payload_sequence = []\n",
    "\n",
    "    cycle_number = 11\n",
    "\n",
    "\n",
    "    for i in payload:\n",
    "        for j in i:\n",
    "            payload_sequence.append(cycle_number)\n",
    "            payload_sequence.append(j)\n",
    "            payload_sequence.append(cycle_number)\n",
    "        cycle_number+=1\n",
    "\n",
    "    return payload_sequence\n",
    "\n",
    "def sort_transcript(transcript):\n",
    "\n",
    "    cycles = [[] for i in range(8)]\n",
    "\n",
    "    split_transcript = transcript.split()\n",
    "    split_transcript = [int(i) for i in split_transcript  if i != '']\n",
    "\n",
    "    for i in range(len(split_transcript)):\n",
    "        \n",
    "        found_motif = split_transcript[i]\n",
    "        \n",
    "        # If we have a payload motif\n",
    "        if found_motif < 9:\n",
    "\n",
    "            # finding the spacers - only for payload cycles\n",
    "            if i > 0:\n",
    "\n",
    "                # Checking for Back Spacer\n",
    "                if split_transcript[i-1] > 10:\n",
    "                    cycle_number = split_transcript[i-1] - 11\n",
    "                    print(split_transcript[i-1])\n",
    "                    print(cycle_number)\n",
    "                    cycles[cycle_number].append(split_transcript[i])\n",
    "\n",
    "                # Checking for Forward Spacer\n",
    "                elif i < len(split_transcript) - 1:\n",
    "                    if split_transcript[i+1] > 10:\n",
    "                        cycle_number = split_transcript[i+1] - 11\n",
    "                        print(split_transcript[i+1])\n",
    "                        print(cycle_number)\n",
    "                        cycles[cycle_number].append(split_transcript[i])\n",
    "\n",
    "            else:\n",
    "                if i < len(split_transcript) - 1:\n",
    "                    # Checking for Forward Spacer\n",
    "                    if split_transcript[i+1] > 10:\n",
    "                        cycle_number = split_transcript[i+1] - 11\n",
    "                        print(split_transcript[i+1])\n",
    "                        print(cycle_number)\n",
    "                        cycles[cycle_number].append(split_transcript[i])   \n",
    "\n",
    "    return cycles\n",
    "\n",
    "\n",
    "\n",
    "def sort_transcript_caller(transcript):\n",
    "\n",
    "    # Looking for spacers instead\n",
    "\n",
    "    cycles = [[] for i in range(8)]\n",
    "\n",
    "    split_transcript = transcript.split()\n",
    "    split_transcript = [int(i) for i in split_transcript  if i != '']\n",
    "\n",
    "    for i in range(len(split_transcript)-1):\n",
    "        current_cycle = 11\n",
    "\n",
    "        found_motif = split_transcript[i]\n",
    "        # Looking for spacers\n",
    "        if found_motif >= current_cycle:\n",
    "            current_cycle = split_transcript[i] - 11\n",
    "            if split_transcript[i+1] < 9:\n",
    "                cycles[current_cycle].append(split_transcript[i+1])\n",
    "    return cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/6894\n",
      "5.602296352386475\n",
      "[([], 0.0), ([1], 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\pytorch_examples\\greedy_decoder.py:67: RuntimeWarning: invalid value encountered in log\n",
      "  for s in range(S):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 1 9 8 10 11 8 11 3 12 13 13 14 1 14 6 16 17 17 18\n",
      " 10 8 10 14 1 14 16 3 16 18 7 18\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "11\n",
      "0\n",
      "11\n",
      "0\n",
      "14\n",
      "3\n",
      "14\n",
      "3\n",
      "14\n",
      "3\n",
      "16\n",
      "5\n",
      "18\n",
      "7\n",
      "[[8, 3], [], [], [1, 6], [], [], [], []]\n",
      "[[], [], [], [1], [], [3], [], [7]]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 4\n",
      "Incorrect motifs caller 0\n",
      "Correct motifs read 2\n",
      "Incorrect motifs read 1\n",
      "\n",
      "5.112450122833252\n",
      "[([11, 5], 0.0), ([11, 5, 1], 0.0)]\n",
      "9 10 6 10 11 3 11 12 7 12 13 14 5 14 5 15 6 16 17 7 6\n",
      " 11 3 11 13 5 13 14 5 14 18 6 18\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "11\n",
      "0\n",
      "12\n",
      "1\n",
      "14\n",
      "3\n",
      "14\n",
      "3\n",
      "15\n",
      "4\n",
      "17\n",
      "6\n",
      "11\n",
      "0\n",
      "13\n",
      "2\n",
      "14\n",
      "3\n",
      "18\n",
      "7\n",
      "[[3], [7], [], [5, 5], [6], [], [7], []]\n",
      "[[3], [], [5], [5], [], [], [], [6]]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 4\n",
      "Incorrect motifs caller 1\n",
      "Correct motifs read 2\n",
      "Incorrect motifs read 2\n",
      "\n",
      "5.761581897735596\n",
      "[([8], 0.0), ([8, 1], 0.0)]\n",
      "9 8 11 1 7 12 13 14 15 2 15 17 7\n",
      " 14 6 14 15 2 15 16 4 16\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "11\n",
      "0\n",
      "11\n",
      "0\n",
      "12\n",
      "1\n",
      "15\n",
      "4\n",
      "17\n",
      "6\n",
      "14\n",
      "3\n",
      "15\n",
      "4\n",
      "16\n",
      "5\n",
      "[[8, 1], [7], [], [], [2], [], [7], []]\n",
      "[[], [], [], [6], [2], [4], [], []]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 2\n",
      "Incorrect motifs caller 3\n",
      "Correct motifs read 1\n",
      "Incorrect motifs read 2\n",
      "\n",
      "8.342117309570312\n",
      "[([], 0.0), ([1], 0.0)]\n",
      "9 13 9 17\n",
      " 13 1 13 14 6 14\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "13\n",
      "2\n",
      "14\n",
      "3\n",
      "[[], [], [], [], [], [], [], []]\n",
      "[[], [], [1], [6], [], [], [], []]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 0\n",
      "Incorrect motifs caller 0\n",
      "Correct motifs read 2\n",
      "Incorrect motifs read 0\n",
      "\n",
      "30.517362594604492\n",
      "[([], 0.0), ([1], 0.0)]\n",
      "5 14 10 10 11 6 11 12 3 13 13 14 15 2 15 5\n",
      " 9 5 9\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "14\n",
      "3\n",
      "11\n",
      "0\n",
      "12\n",
      "1\n",
      "15\n",
      "4\n",
      "15\n",
      "4\n",
      "[[6], [3], [], [5], [2, 5], [], [], []]\n",
      "[[], [], [], [], [], [], [], []]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 4\n",
      "Incorrect motifs caller 1\n",
      "Correct motifs read 0\n",
      "Incorrect motifs read 0\n",
      "\n",
      "4.81297492980957\n",
      "[([], 0.0), ([1], 0.0)]\n",
      "9 4 9 10 10 11 2 11 12 6 12 13 5 13 14 1 14 15 16 17 3 18 8\n",
      " 11 2 11 12 6 12 14 1 14 15 8 15 16 3 16 18 8 18\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "11\n",
      "0\n",
      "12\n",
      "1\n",
      "13\n",
      "2\n",
      "14\n",
      "3\n",
      "17\n",
      "6\n",
      "18\n",
      "7\n",
      "11\n",
      "0\n",
      "12\n",
      "1\n",
      "14\n",
      "3\n",
      "15\n",
      "4\n",
      "16\n",
      "5\n",
      "18\n",
      "7\n",
      "[[2], [6], [5], [1], [], [], [3], [8]]\n",
      "[[2], [6], [], [1], [8], [3], [], [8]]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 2\n",
      "Incorrect motifs caller 4\n",
      "Correct motifs read 2\n",
      "Incorrect motifs read 4\n",
      "\n",
      "13.64005184173584\n",
      "[([], 0.0), ([1], 0.0)]\n",
      "4 9 10 6 11 11 12 5 12 2 14 3 4 15 16 3 17\n",
      " 11 8 11 14 3 14\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "11\n",
      "0\n",
      "12\n",
      "1\n",
      "12\n",
      "1\n",
      "14\n",
      "3\n",
      "15\n",
      "4\n",
      "16\n",
      "5\n",
      "11\n",
      "0\n",
      "14\n",
      "3\n",
      "[[6], [5, 2], [], [3], [4], [3], [], []]\n",
      "[[8], [], [], [3], [], [], [], []]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 3\n",
      "Incorrect motifs caller 3\n",
      "Correct motifs read 1\n",
      "Incorrect motifs read 1\n",
      "\n",
      "4.949967861175537\n",
      "[([], 0.0), ([1], 0.0)]\n",
      "9 2 10 11 3 12 13 7 13 14 3 15 5 16 18 5\n",
      " 11 3 11 13 7 13 14 3 14 17 3 17\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "11\n",
      "0\n",
      "13\n",
      "2\n",
      "14\n",
      "3\n",
      "15\n",
      "4\n",
      "18\n",
      "7\n",
      "11\n",
      "0\n",
      "13\n",
      "2\n",
      "14\n",
      "3\n",
      "17\n",
      "6\n",
      "[[3], [], [7], [3], [5], [], [], [5]]\n",
      "[[3], [], [7], [3], [], [], [3], []]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 3\n",
      "Incorrect motifs caller 2\n",
      "Correct motifs read 2\n",
      "Incorrect motifs read 2\n",
      "\n",
      "4.074265956878662\n",
      "[([], 0.0), ([1], 0.0)]\n",
      "11 12 4 12 13\n",
      " 10 2 10 11 4 11 12 4 12\n",
      "[11, 3, 11, 11, 6, 11, 11, 7, 11, 11, 8, 11, 12, 3, 12, 12, 4, 12, 12, 5, 12, 12, 8, 12, 13, 1, 13, 13, 2, 13, 13, 4, 13, 13, 6, 13, 14, 1, 14, 14, 2, 14, 14, 5, 14, 14, 6, 14, 15, 4, 15, 15, 5, 15, 15, 6, 15, 15, 8, 15, 16, 1, 16, 16, 2, 16, 16, 5, 16, 16, 7, 16, 17, 1, 17, 17, 3, 17, 17, 4, 17, 17, 7, 17, 18, 2, 18, 18, 4, 18, 18, 5, 18, 18, 7, 18]\n",
      "\n",
      "12\n",
      "1\n",
      "11\n",
      "0\n",
      "12\n",
      "1\n",
      "[[], [4], [], [], [], [], [], []]\n",
      "[[4], [4], [], [], [], [], [], []]\n",
      "[[3, 6, 7, 8], [3, 4, 5, 8], [1, 2, 4, 6], [1, 2, 5, 6], [4, 5, 6, 8], [1, 2, 5, 7], [1, 3, 4, 7], [2, 4, 5, 7]]\n",
      "\n",
      "Correct motifs caller 1\n",
      "Incorrect motifs caller 0\n",
      "Correct motifs read 1\n",
      "Incorrect motifs read 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntest_loss /= len(X_test)\\ntest_accuracy = np.mean(distances_arr)\\nmotifs_identifed = np.mean(motifs_identifed_arr)\\nprint(f\"Test Loss: {test_loss:.4f}, Test Edit Distance: {test_accuracy:.4f}, Motifs Identified: {motifs_identifed:.4f}\")\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "payloads = dataset_df['Payload'].tolist()\n",
    "\n",
    "# Test Loop\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "distances_arr = []\n",
    "motifs_identifed_arr = []\n",
    "greedy_transcripts = []\n",
    "actual_transcripts = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test[1:10])):\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Processing {i}/{len(X_test)}\")\n",
    "\n",
    "        test_sequence, target_sequence = torch.tensor(X_test[i]).to(device), torch.tensor(y_test[i]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "        model_output_timestep = model(test_sequence) # Getting model output\n",
    "\n",
    "        input_lengths = torch.tensor(X_test[i].shape[0])\n",
    "        target_lengths = torch.tensor(len(target_sequence))\n",
    "\n",
    "        loss = ctc_loss(model_output_timestep, target_sequence, input_lengths, target_lengths)\n",
    "\n",
    "        print(loss.item())\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        greedy_result = greedy_decoder(model_output_timestep)\n",
    "        beam_result = beam_search_decoder(model_output_timestep)\n",
    "        greedy_transcript = \" \".join(greedy_result)\n",
    "        actual_transcript = get_actual_transcript(target_sequence)\n",
    "        greedy_transcripts.append(greedy_transcript)\n",
    "        actual_transcripts.append(actual_transcript)\n",
    "        payload_spacer = create_payload_spacer_sequence(payloads[i])\n",
    "\n",
    "        print(greedy_result)\n",
    "        print(actual_transcript)\n",
    "        print(payload_spacer)\n",
    "        print()\n",
    "\n",
    "\n",
    "        cycles_motif_caller = sort_transcript(greedy_result)\n",
    "        cycles_motif_read = sort_transcript(actual_transcript)\n",
    "        \n",
    "\n",
    "        print(cycles_motif_caller)\n",
    "        print(cycles_motif_read)\n",
    "        print(payloads[i])\n",
    "        print()\n",
    "\n",
    "        correct_motifs_predicted_motif_read = 0\n",
    "        correct_motifs_predicted_motif_caller = 0\n",
    "\n",
    "        incorrect_motifs_predicted_motif_read = 0\n",
    "        incorrect_motifs_predicted_motif_caller = 0\n",
    "\n",
    "        for i,j,k in zip(cycles_motif_read, cycles_motif_caller, payloads[i]):\n",
    "\n",
    "            correct_motifs_predicted_motif_read += len(set(i).intersection(set(k)))\n",
    "            correct_motifs_predicted_motif_caller += len(set(j).intersection(set(k)))\n",
    "            incorrect_motifs_predicted_motif_read += len(set(i).difference(set(k)))\n",
    "            incorrect_motifs_predicted_motif_caller += len(set(j).difference(set(k)))\n",
    "\n",
    "        print(f\"Correct motifs caller {correct_motifs_predicted_motif_caller}\")\n",
    "        print(f\"Incorrect motifs caller {incorrect_motifs_predicted_motif_caller}\")\n",
    "        print(f\"Correct motifs read {correct_motifs_predicted_motif_read}\")\n",
    "        print(f\"Incorrect motifs read {incorrect_motifs_predicted_motif_read}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        motif_err = torchaudio.functional.edit_distance(actual_transcript, greedy_transcript) / len(actual_transcript)\n",
    "        distances_arr.append(motif_err)\n",
    "\n",
    "        motifs_identifed = get_motifs_identified(actual_transcript, greedy_transcript)\n",
    "        motifs_identifed_arr.append(motifs_identifed)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "test_loss /= len(X_test)\n",
    "test_accuracy = np.mean(distances_arr)\n",
    "motifs_identifed = np.mean(motifs_identifed_arr)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Edit Distance: {test_accuracy:.4f}, Motifs Identified: {motifs_identifed:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.1066, -16.0322, -15.7049, -17.1003, -16.0035, -15.6052, -20.9624,\n",
       "        -16.2155, -15.0726,  -3.8783,  -7.3401, -15.4738, -16.0508, -17.0568,\n",
       "        -14.7530, -17.4408, -16.7398, -17.2372, -16.6317], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_timestep[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
